events {
    worker_connections 1024;
}

http {
    upstream ml_inference {
        server ml-inference-api:8001;
    }
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    
    # File upload limits
    client_max_body_size 500M;
    
    server {
        listen 80;
        server_name 155.138.239.131;
        
        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        
        # API proxy
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://ml_inference;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts for long-running inference
            proxy_connect_timeout 60s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
        }
        
        # Health check
        location /health {
            proxy_pass http://ml_inference/api/health;
        }
        
        # Static files (if needed)
        location /static/ {
            alias /app/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
        
        # Logs
        access_log /var/log/nginx/vru_access.log;
        error_log /var/log/nginx/vru_error.log;
    }
}
