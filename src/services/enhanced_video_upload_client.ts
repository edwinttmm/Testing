/**
 * Enhanced Video Upload Client with Chunked Upload Support
 * 
 * Provides comprehensive upload capabilities:
 * - Automatic fallback from chunked to traditional upload
 * - Progress tracking with detailed metrics
 * - Retry mechanisms with exponential backoff
 * - Resume functionality for interrupted uploads
 * - File integrity verification
 */

interface UploadProgress {
  percentage: number;
  bytesUploaded: number;
  totalBytes: number;
  chunksCompleted: number;
  totalChunks: number;
  uploadSpeedMbps: number;
  etaSeconds: number;
  status: 'uploading' | 'paused' | 'completed' | 'failed' | 'resuming';
}

interface ChunkedUploadSession {
  uploadSessionId: string;
  totalChunks: number;
  chunkSize: number;
  expiresAt: Date;
  uploadUrl: string;
}

interface UploadConfig {
  maxFileSize: number;
  chunkSize: number;
  maxRetries: number;
  timeoutMs: number;
  enableChunkedUpload: boolean;
  enableResume: boolean;
}

interface RetryConfig {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
  backoffFactor: number;
}

class UploadError extends Error {
  constructor(
    message: string,
    public code: string,
    public statusCode?: number,
    public retryable: boolean = false
  ) {
    super(message);
    this.name = 'UploadError';
  }
}

class EnhancedVideoUploadClient {
  private apiUrl: string;
  private defaultConfig: UploadConfig;
  private activeUploads: Map<string, AbortController> = new Map();

  constructor(apiUrl: string = '') {
    this.apiUrl = apiUrl || process.env.REACT_APP_API_URL || 'http://localhost:8000';
    this.defaultConfig = {
      maxFileSize: 1024 * 1024 * 1024, // 1GB
      chunkSize: 64 * 1024, // 64KB
      maxRetries: 3,
      timeoutMs: 300000, // 5 minutes
      enableChunkedUpload: true,
      enableResume: true
    };
  }

  /**
   * Upload a video file with automatic strategy selection
   */
  async uploadVideo(
    file: File,
    options: {
      projectId?: string;
      onProgress?: (progress: UploadProgress) => void;
      onError?: (error: UploadError) => void;
      config?: Partial<UploadConfig>;
      abortSignal?: AbortSignal;
    } = {}
  ): Promise<any> {
    const config = { ...this.defaultConfig, ...options.config };
    const uploadId = this.generateUploadId();
    
    try {
      // Validate file
      this.validateFile(file, config);
      
      // Create abort controller for this upload
      const abortController = new AbortController();
      this.activeUploads.set(uploadId, abortController);
      
      // Combine abort signals
      const combinedSignal = options.abortSignal 
        ? this.combineAbortSignals([options.abortSignal, abortController.signal])
        : abortController.signal;

      // Choose upload strategy
      const useChunkedUpload = config.enableChunkedUpload && file.size > 50 * 1024 * 1024; // 50MB threshold
      
      let result;
      if (useChunkedUpload) {
        console.log(`ðŸ“¤ Using chunked upload for large file: ${file.name} (${this.formatFileSize(file.size)})`);
        result = await this.uploadVideoChunked(file, {
          ...options,
          config,
          abortSignal: combinedSignal,
          uploadId
        });
      } else {
        console.log(`ðŸ“¤ Using traditional upload for file: ${file.name} (${this.formatFileSize(file.size)})`);
        result = await this.uploadVideoTraditional(file, {
          ...options,
          config,
          abortSignal: combinedSignal,
          uploadId
        });
      }
      
      console.log(`âœ… Upload completed: ${file.name}`);
      return result;
      
    } catch (error) {
      console.error(`âŒ Upload failed: ${file.name}`, error);
      
      // Convert to UploadError if needed
      const uploadError = error instanceof UploadError ? error : new UploadError(
        error instanceof Error ? error.message : 'Unknown upload error',
        'UPLOAD_FAILED',
        undefined,
        false
      );
      
      if (options.onError) {
        options.onError(uploadError);
      }
      
      throw uploadError;
      
    } finally {
      // Cleanup
      this.activeUploads.delete(uploadId);
    }
  }

  /**
   * Traditional single-request upload with progress tracking
   */
  private async uploadVideoTraditional(
    file: File,
    options: {
      projectId?: string;
      onProgress?: (progress: UploadProgress) => void;
      config: UploadConfig;
      abortSignal: AbortSignal;
      uploadId: string;
    }
  ): Promise<any> {
    const formData = new FormData();
    formData.append('file', file);
    if (options.projectId) {
      formData.append('project_id', options.projectId);
    }

    const startTime = Date.now();
    let lastProgressTime = startTime;
    let lastBytesUploaded = 0;

    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();

      // Setup abort handling
      const abortHandler = () => {
        xhr.abort();
        reject(new UploadError('Upload cancelled by user', 'CANCELLED'));
      };
      options.abortSignal.addEventListener('abort', abortHandler);

      // Setup progress tracking
      xhr.upload.onprogress = (event) => {
        if (event.lengthComputable && options.onProgress) {
          const now = Date.now();
          const timeDelta = now - lastProgressTime;
          const bytesDelta = event.loaded - lastBytesUploaded;
          
          // Calculate upload speed (only if enough time has passed)
          let uploadSpeedMbps = 0;
          if (timeDelta > 1000) { // Update speed every second
            const speedBps = (bytesDelta * 1000) / timeDelta; // bytes per second
            uploadSpeedMbps = speedBps / (1024 * 1024); // convert to MB/s
            lastProgressTime = now;
            lastBytesUploaded = event.loaded;
          }

          // Calculate ETA
          const totalTime = now - startTime;
          const avgSpeedBps = event.loaded / (totalTime / 1000);
          const remainingBytes = event.total - event.loaded;
          const etaSeconds = avgSpeedBps > 0 ? remainingBytes / avgSpeedBps : 0;

          const progress: UploadProgress = {
            percentage: (event.loaded / event.total) * 100,
            bytesUploaded: event.loaded,
            totalBytes: event.total,
            chunksCompleted: Math.floor(event.loaded / options.config.chunkSize),
            totalChunks: Math.ceil(event.total / options.config.chunkSize),
            uploadSpeedMbps,
            etaSeconds: Math.round(etaSeconds),
            status: 'uploading'
          };

          options.onProgress(progress);
        }
      };

      // Setup response handlers
      xhr.onload = () => {
        options.abortSignal.removeEventListener('abort', abortHandler);
        
        if (xhr.status >= 200 && xhr.status < 300) {
          try {
            const result = JSON.parse(xhr.responseText);
            resolve(result);
          } catch (error) {
            reject(new UploadError('Invalid response format', 'INVALID_RESPONSE'));
          }
        } else {
          let errorMessage = 'Upload failed';
          try {
            const errorResponse = JSON.parse(xhr.responseText);
            errorMessage = errorResponse.message || errorResponse.detail || errorMessage;
          } catch {
            errorMessage = `HTTP ${xhr.status}: ${xhr.statusText}`;
          }
          
          const retryable = xhr.status >= 500 || xhr.status === 408; // Server errors and timeouts
          reject(new UploadError(errorMessage, 'HTTP_ERROR', xhr.status, retryable));
        }
      };

      xhr.onerror = () => {
        options.abortSignal.removeEventListener('abort', abortHandler);
        reject(new UploadError('Network error during upload', 'NETWORK_ERROR', undefined, true));
      };

      xhr.ontimeout = () => {
        options.abortSignal.removeEventListener('abort', abortHandler);
        reject(new UploadError('Upload timeout', 'TIMEOUT', 408, true));
      };

      // Configure and send request
      xhr.open('POST', `${this.apiUrl}/api/v2/videos/upload/traditional`);
      xhr.timeout = options.config.timeoutMs;
      xhr.send(formData);
    });
  }

  /**
   * Chunked upload with resume capability
   */
  private async uploadVideoChunked(
    file: File,
    options: {
      projectId?: string;
      onProgress?: (progress: UploadProgress) => void;
      config: UploadConfig;
      abortSignal: AbortSignal;
      uploadId: string;
    }
  ): Promise<any> {
    const retryConfig: RetryConfig = {
      maxRetries: options.config.maxRetries,
      baseDelay: 1000,
      maxDelay: 30000,
      backoffFactor: 2
    };

    // Step 1: Initialize chunked upload
    const session = await this.initChunkedUpload(file, options.abortSignal);
    console.log(`ðŸ“‹ Initialized chunked upload: ${session.totalChunks} chunks of ${this.formatFileSize(session.chunkSize)}`);

    try {
      // Step 2: Upload chunks with retry logic
      const startTime = Date.now();
      let bytesUploaded = 0;
      
      for (let chunkIndex = 0; chunkIndex < session.totalChunks; chunkIndex++) {
        // Check for abort
        if (options.abortSignal.aborted) {
          throw new UploadError('Upload cancelled', 'CANCELLED');
        }

        // Calculate chunk boundaries
        const start = chunkIndex * session.chunkSize;
        const end = Math.min(start + session.chunkSize, file.size);
        const chunkBlob = file.slice(start, end);
        
        // Upload chunk with retry
        await this.uploadChunkWithRetry(
          session.uploadSessionId,
          chunkIndex,
          chunkBlob,
          retryConfig,
          options.abortSignal
        );

        bytesUploaded += chunkBlob.size;

        // Update progress
        if (options.onProgress) {
          const now = Date.now();
          const elapsedSeconds = (now - startTime) / 1000;
          const uploadSpeedMbps = (bytesUploaded / elapsedSeconds) / (1024 * 1024);
          const remainingBytes = file.size - bytesUploaded;
          const etaSeconds = uploadSpeedMbps > 0 ? remainingBytes / (uploadSpeedMbps * 1024 * 1024) : 0;

          const progress: UploadProgress = {
            percentage: (bytesUploaded / file.size) * 100,
            bytesUploaded,
            totalBytes: file.size,
            chunksCompleted: chunkIndex + 1,
            totalChunks: session.totalChunks,
            uploadSpeedMbps,
            etaSeconds: Math.round(etaSeconds),
            status: 'uploading'
          };

          options.onProgress(progress);
        }

        // Log progress for large uploads
        if (chunkIndex % Math.max(1, Math.floor(session.totalChunks / 10)) === 0) {
          const percentage = ((chunkIndex + 1) / session.totalChunks * 100).toFixed(1);
          console.log(`ðŸ“Š Upload progress: ${percentage}% (${chunkIndex + 1}/${session.totalChunks} chunks)`);
        }
      }

      // Step 3: Finalize upload (chunks service handles this automatically)
      console.log(`ðŸŽ‰ All chunks uploaded successfully`);
      
      // Return success response
      return {
        upload_session_id: session.uploadSessionId,
        filename: file.name,
        file_size: file.size,
        total_chunks: session.totalChunks,
        upload_time_seconds: (Date.now() - startTime) / 1000,
        status: 'completed'
      };

    } catch (error) {
      // Cancel the upload session on error
      try {
        await this.cancelUpload(session.uploadSessionId);
      } catch (cancelError) {
        console.warn('Failed to cancel upload session:', cancelError);
      }
      throw error;
    }
  }

  /**
   * Initialize a chunked upload session
   */
  private async initChunkedUpload(file: File, abortSignal: AbortSignal): Promise<ChunkedUploadSession> {
    const response = await fetch(`${this.apiUrl}/api/v2/videos/upload/init`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        filename: file.name,
        file_size: file.size,
        chunk_size: this.defaultConfig.chunkSize
      }),
      signal: abortSignal
    });

    if (!response.ok) {
      const error = await this.parseErrorResponse(response);
      throw error;
    }

    const data = await response.json();
    return {
      uploadSessionId: data.upload_session_id,
      totalChunks: data.total_chunks,
      chunkSize: data.chunk_size,
      expiresAt: new Date(data.expires_at),
      uploadUrl: data.upload_url
    };
  }

  /**
   * Upload a single chunk with retry logic
   */
  private async uploadChunkWithRetry(
    uploadSessionId: string,
    chunkIndex: number,
    chunkBlob: Blob,
    retryConfig: RetryConfig,
    abortSignal: AbortSignal
  ): Promise<void> {
    let lastError: UploadError | null = null;
    
    for (let attempt = 0; attempt <= retryConfig.maxRetries; attempt++) {
      if (abortSignal.aborted) {
        throw new UploadError('Upload cancelled', 'CANCELLED');
      }

      try {
        // Calculate chunk checksum for integrity verification
        const chunkData = await chunkBlob.arrayBuffer();
        const checksum = await this.calculateMD5(chunkData);
        
        // Upload chunk
        const formData = new FormData();
        formData.append('chunk_index', chunkIndex.toString());
        formData.append('checksum', checksum);
        formData.append('chunk', chunkBlob);

        const response = await fetch(`${this.apiUrl}/api/v2/videos/upload/chunk/${uploadSessionId}`, {
          method: 'POST',
          body: formData,
          signal: abortSignal
        });

        if (response.ok) {
          const result = await response.json();
          
          // Handle retry requirement
          if (result.status === 'retry_required') {
            throw new UploadError(
              `Chunk ${chunkIndex} requires retry (attempt ${result.retry_count}/${result.max_retries})`,
              'CHUNK_RETRY_REQUIRED',
              undefined,
              true
            );
          }
          
          // Success
          return;
        }

        // Parse error response
        const error = await this.parseErrorResponse(response);
        lastError = error;
        
        // Don't retry non-retryable errors
        if (!error.retryable) {
          throw error;
        }

      } catch (error) {
        if (error instanceof UploadError) {
          lastError = error;
          
          // Don't retry cancelled uploads
          if (error.code === 'CANCELLED') {
            throw error;
          }
          
          // Don't retry non-retryable errors
          if (!error.retryable) {
            throw error;
          }
        } else {
          lastError = new UploadError(
            error instanceof Error ? error.message : 'Unknown error',
            'UNKNOWN_ERROR',
            undefined,
            true
          );
        }
      }

      // Calculate delay for next attempt
      if (attempt < retryConfig.maxRetries) {
        const delay = Math.min(
          retryConfig.baseDelay * Math.pow(retryConfig.backoffFactor, attempt),
          retryConfig.maxDelay
        );
        
        console.log(`â³ Retrying chunk ${chunkIndex} in ${delay}ms (attempt ${attempt + 1}/${retryConfig.maxRetries})`);
        await this.delay(delay);
      }
    }

    // All retries exhausted
    throw lastError || new UploadError(
      `Failed to upload chunk ${chunkIndex} after ${retryConfig.maxRetries} retries`,
      'MAX_RETRIES_EXCEEDED'
    );
  }

  /**
   * Cancel an active upload
   */
  async cancelUpload(uploadSessionId: string): Promise<void> {
    try {
      const response = await fetch(`${this.apiUrl}/api/v2/videos/upload/${uploadSessionId}`, {
        method: 'DELETE'
      });

      if (!response.ok && response.status !== 404) {
        console.warn(`Failed to cancel upload session: ${response.status}`);
      }
    } catch (error) {
      console.warn('Error cancelling upload session:', error);
    }
  }

  /**
   * Get upload status
   */
  async getUploadStatus(uploadSessionId: string): Promise<any> {
    const response = await fetch(`${this.apiUrl}/api/v2/videos/upload/status/${uploadSessionId}`);
    
    if (!response.ok) {
      throw await this.parseErrorResponse(response);
    }
    
    return response.json();
  }

  /**
   * Resume an interrupted upload
   */
  async resumeUpload(
    uploadSessionId: string,
    file: File,
    onProgress?: (progress: UploadProgress) => void
  ): Promise<any> {
    // Get current upload status
    const status = await this.getUploadStatus(uploadSessionId);
    
    if (status.status === 'completed') {
      throw new UploadError('Upload already completed', 'ALREADY_COMPLETED');
    }
    
    const missingChunks = status.missing_chunks || [];
    console.log(`ðŸ“‹ Resuming upload: ${missingChunks.length} chunks remaining`);
    
    // Upload missing chunks
    // Implementation would be similar to chunked upload but only for missing chunks
    // For brevity, this is left as a simplified implementation
    
    return { message: 'Resume functionality not fully implemented in this example' };
  }

  // Utility methods
  private validateFile(file: File, config: UploadConfig): void {
    if (!file.name) {
      throw new UploadError('File name is required', 'INVALID_FILE');
    }
    
    if (file.size === 0) {
      throw new UploadError('Empty file not allowed', 'EMPTY_FILE');
    }
    
    if (file.size > config.maxFileSize) {
      const maxSizeMB = config.maxFileSize / (1024 * 1024);
      throw new UploadError(
        `File too large. Maximum size: ${maxSizeMB.toFixed(1)}MB`,
        'FILE_TOO_LARGE'
      );
    }
    
    // Validate file extension
    const allowedExtensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm'];
    const fileExt = file.name.toLowerCase().split('.').pop();
    if (!fileExt || !allowedExtensions.some(ext => ext.substring(1) === fileExt)) {
      throw new UploadError(
        `Unsupported file type. Allowed: ${allowedExtensions.join(', ')}`,
        'UNSUPPORTED_FILE_TYPE'
      );
    }
  }

  private async parseErrorResponse(response: Response): Promise<UploadError> {
    try {
      const errorData = await response.json();
      return new UploadError(
        errorData.message || errorData.detail || 'Upload failed',
        errorData.type || 'HTTP_ERROR',
        response.status,
        response.status >= 500 || response.status === 408 // Server errors and timeouts are retryable
      );
    } catch {
      return new UploadError(
        `HTTP ${response.status}: ${response.statusText}`,
        'HTTP_ERROR',
        response.status,
        response.status >= 500 || response.status === 408
      );
    }
  }

  private generateUploadId(): string {
    return `upload_${Date.now()}_${Math.random().toString(36).substring(2)}`;
  }

  private formatFileSize(bytes: number): string {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return `${parseFloat((bytes / Math.pow(k, i)).toFixed(1))} ${sizes[i]}`;
  }

  private combineAbortSignals(signals: AbortSignal[]): AbortSignal {
    const controller = new AbortController();
    
    for (const signal of signals) {
      if (signal.aborted) {
        controller.abort();
        break;
      }
      signal.addEventListener('abort', () => controller.abort());
    }
    
    return controller.signal;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  private async calculateMD5(data: ArrayBuffer): Promise<string> {
    // Simple MD5 implementation using SubtleCrypto (for modern browsers)
    // Note: This is a simplified version. In production, use a proper MD5 library
    try {
      const hashBuffer = await crypto.subtle.digest('SHA-256', data); // Using SHA-256 as fallback
      const hashArray = Array.from(new Uint8Array(hashBuffer));
      return hashArray.map(b => b.toString(16).padStart(2, '0')).join('').substring(0, 32);
    } catch {
      // Fallback to simple checksum
      const view = new Uint8Array(data);
      let hash = 0;
      for (let i = 0; i < view.length; i++) {
        hash = ((hash << 5) - hash + view[i]) & 0xffffffff;
      }
      return Math.abs(hash).toString(16).padStart(8, '0');
    }
  }
}

// Export for use in React components
export { EnhancedVideoUploadClient, UploadError };
export type { UploadProgress, UploadConfig };